{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia Classification Improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements an improved version of the Pneumonia classification using both a VGG16 pretrained model and a custom CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the base directory\n",
    "base_dir = '../input/chest-xray-pneumonia/chest_xray/'\n",
    "\n",
    "train_pneumonia_dir = os.path.join(base_dir, 'train/PNEUMONIA/')\n",
    "train_normal_dir = os.path.join(base_dir, 'train/NORMAL/')\n",
    "test_pneumonia_dir = os.path.join(base_dir, 'test/PNEUMONIA/')\n",
    "test_normal_dir = os.path.join(base_dir, 'test/NORMAL/')\n",
    "val_pneumonia_dir = os.path.join(base_dir, 'val/PNEUMONIA/')\n",
    "val_normal_dir = os.path.join(base_dir, 'val/NORMAL/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess images\n",
    "def preprocess_image(image_list, img_size=224):\n",
    "    X = []\n",
    "    y = []\n",
    "    for image in image_list:\n",
    "        try:\n",
    "            img = cv2.imread(image)\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            X.append(img)\n",
    "            if 'NORMAL' in image:\n",
    "                y.append(0)\n",
    "            else:\n",
    "                y.append(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image}: {e}\")\n",
    "            continue\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting and preprocessing the dataset\n",
    "train_pn = [os.path.join(train_pneumonia_dir, f) for f in os.listdir(train_pneumonia_dir)]\n",
    "train_normal = [os.path.join(train_normal_dir, f) for f in os.listdir(train_normal_dir)]\n",
    "test_pn = [os.path.join(test_pneumonia_dir, f) for f in os.listdir(test_pneumonia_dir)]\n",
    "test_normal = [os.path.join(test_normal_dir, f) for f in os.listdir(test_normal_dir)]\n",
    "val_pn = [os.path.join(val_pneumonia_dir, f) for f in os.listdir(val_pneumonia_dir)]\n",
    "val_normal = [os.path.join(val_normal_dir, f) for f in os.listdir(val_normal_dir)]\n",
    "\n",
    "train_imgs = train_pn + train_normal\n",
    "test_imgs = test_pn + test_normal\n",
    "val_imgs = val_pn + val_normal\n",
    "\n",
    "random.shuffle(train_imgs)\n",
    "random.shuffle(test_imgs)\n",
    "random.shuffle(val_imgs)\n",
    "\n",
    "X_learn, y_learn = preprocess_image(train_imgs)\n",
    "X_test, y_test = preprocess_image(test_imgs)\n",
    "X_validation, y_validation = preprocess_image(val_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building - VGG16 pretrained model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model_vgg16 = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_vgg16.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_vgg16_model.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the VGG16 model\n",
    "history_vgg16 = model_vgg16.fit(\n",
    "    datagen.flow(X_learn, y_learn, batch_size=32),\n",
    "    epochs=10,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the VGG16 model\n",
    "vgg16_results = model_vgg16.evaluate(X_test, y_test)\n",
    "print(f\"VGG16 Model - Test Loss: {vgg16_results[0]}, Test Accuracy: {vgg16_results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building - Conventional CNN model\n",
    "model_cnn = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the conventional CNN model\n",
    "history_cnn = model_cnn.fit(\n",
    "    datagen.flow(X_learn, y_learn, batch_size=32),\n",
    "    epochs=10,\n",
    "    validation_data=(X_validation, y_validation),\n",
    "    callbacks=[early_stopping, model_checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the conventional CNN model\n",
    "cnn_results = model_cnn.evaluate(X_test, y_test)\n",
    "print(f\"CNN Model - Test Loss: {cnn_results[0]}, Test Accuracy: {cnn_results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions and classification report\n",
    "pred_vgg16 = (model_vgg16.predict(X_test) > 0.5).astype(int)\n",
    "pred_cnn = (model_cnn.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "print(\"VGG16 Model Classification Report\")\n",
    "print(classification_report(y_test, pred_vgg16))\n",
    "\n",
    "print(\"Conventional CNN Model Classification Report\")\n",
    "print(classification_report(y_test, pred_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for VGG16\n",
    "cm_vgg16 = confusion_matrix(y_test, pred_vgg16)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"VGG16 Confusion Matrix\")\n",
    "sns.heatmap(cm_vgg16, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for CNN\n",
    "cm_cnn = confusion_matrix(y_test, pred_cnn)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"CNN Confusion Matrix\")\n",
    "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models\n",
    "model_vgg16.save('vgg16_model.h5')\n",
    "model_cnn.save('cnn_model.h5')\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
